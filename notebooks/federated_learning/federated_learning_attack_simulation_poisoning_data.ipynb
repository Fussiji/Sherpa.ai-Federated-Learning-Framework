{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Federated learning: Simulation of data poisoning attack\n",
    "\n",
    "In this notebook provide a simulation of a simple data poisoning federated attack. We use a simple first approach \n",
    "which consists of shuffling the training labels of some number of clients which become adversarial ones.\n",
    "\n",
    "The aim of this notebook is to present the class `FederatedDataAttack` implemented in [federated_attack.py](https://github.com/sherpaai/Sherpa.ai-Federated-Learning-Framework/blob/master/shfl/private/federated_attack.py) whose goal is to implement any attack on the federated data. \n",
    "For more information about basic federated learning concepts refer to the [Basic Concepts Notebook](./federated_learning_basic_concepts.ipynb).\n",
    "\n",
    "For the simulation we use [Emnist](https://www.nist.gov/itl/products-and-services/emnist-dataset) Digits dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from shfl.data_base import Emnist\n",
    "from shfl.data_distribution import NonIidDataDistribution\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "\n",
    "database = Emnist()\n",
    "train_data, train_labels, test_data, test_labels = database.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that, we distribute the data among the client nodes using a non-iid distribution over 10% of the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "noniid_distribution = NonIidDataDistribution(database)\n",
    "federated_data, test_data, test_labels = noniid_distribution.get_federated_data(num_nodes=20, percent=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we are ready to apply some data attack to some nodes. \n",
    "For this simulation, we choose to apply data poisoning to the 20% of the nodes. \n",
    "For that purpose, we implement the interface `FederatedTransformation` with a shuffling of the training labels of `federated_data` and create `FederatedPoisoninigDataAttack`, which implements `FederatedDataAttack` with a data poisoning in a certain percentage of the nodes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shfl.private.federated_operation import FederatedTransformation\n",
    "from shfl.private.federated_attack import FederatedDataAttack\n",
    "\n",
    "random.seed(123)\n",
    "\n",
    "class ShuffleNode(FederatedTransformation):\n",
    "    def apply(self, labeled_data):\n",
    "        random.shuffle(labeled_data.label)\n",
    "\n",
    "class FederatedPoisoningDataAttack(FederatedDataAttack):\n",
    "    def __init__(self, percentage):\n",
    "        super().__init__()\n",
    "        self._percentage = percentage\n",
    "        self._adversaries = []\n",
    "\n",
    "    @property\n",
    "    def adversaries(self):\n",
    "        return self._adversaries\n",
    "\n",
    "    def apply_attack(self, federated_data):\n",
    "        num_nodes = federated_data.num_nodes()\n",
    "        list_nodes = np.arange(num_nodes)\n",
    "        self._adversaries = random.sample(list(list_nodes), k=int(self._percentage / 100 * num_nodes))\n",
    "        boolean_adversaries = [1 if x in self._adversaries else 0 for x in list_nodes]\n",
    "\n",
    "        for node, boolean in zip(federated_data, boolean_adversaries):\n",
    "            if boolean:\n",
    "                node.apply_data_transformation(ShuffleNode())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a `FederatedPoisoningDataAttack` object with percentage set to 20% and apply the attack over `federated_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "simple_attack = FederatedPoisoningDataAttack(percentage=20)\n",
    "simple_attack.apply_attack(federated_data = federated_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get the adversarial nodes in order to show the attack applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "adversarial_nodes = simple_attack.adversaries\n",
    "adversarial_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to show the effect of the attack, we select one adversarial client and an index position and show the data and the label associated with this image. \n",
    "We change data access protection (see [FederatedData](https://github.com/sherpaai/Sherpa.ai-Federated-Learning-Framework/blob/master/shfl/private/federated_operation.py)) in order to access the data. \n",
    "Due to the nature of the data poisoning (random shuffle) it is possible that for some specific data the label does match, but in most cases it does not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from shfl.private.data import UnprotectedAccess\n",
    "\n",
    "adversarial_index = 0\n",
    "data_index = 10\n",
    "\n",
    "federated_data.configure_data_access(UnprotectedAccess())\n",
    "\n",
    "plt.imshow(federated_data[adversarial_nodes[adversarial_index]].query().data[data_index])\n",
    "print(federated_data[adversarial_index].query().label[data_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we can train a FL model among these clients (adversarial and regular ones) using a specific aggregation operator. For more information please visit [Basic Concepts Notebook](./federated_learning_basic_concepts.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
