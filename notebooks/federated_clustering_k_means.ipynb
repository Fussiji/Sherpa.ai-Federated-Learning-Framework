{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised federated learning: K-means clustering\n",
    "\n",
    "The present notebook tackles the problem of *unsupervised* learning in a federated configuration. \n",
    "In particular, a K-Means clustering is used from the `sklearn` library (see [this link](https://scikit-learn.org/stable/modules/clustering.html#k-means)).\n",
    "\n",
    "The framework provides some functions to load the [Iris](https://archive.ics.uci.edu/ml/datasets/iris) dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import shfl\n",
    "import numpy as np\n",
    "from shfl.data_base.iris import Iris\n",
    "\n",
    "\n",
    "# Assign database:\n",
    "database = Iris()\n",
    "\n",
    "train_data, train_labels, test_data, test_labels = database.load_data()\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)\n",
    "\n",
    "# Visualize train data: \n",
    "fig, ax = plt.subplots(1,2, figsize=(16,8))\n",
    "fig.suptitle(\"Iris database\", fontsize=20)\n",
    "ax[0].set_title('True labels', fontsize=18)\n",
    "ax[0].scatter(train_data[:, 0], train_data[:, 1], c=train_labels, s=150, edgecolor='k', cmap=\"plasma\")\n",
    "ax[0].set_xlabel('Sepal length', fontsize=18)\n",
    "ax[0].set_ylabel('Sepal width', fontsize=18)\n",
    "ax[0].tick_params(direction='in', length=10, width=5, colors='k', labelsize=20)\n",
    "\n",
    "ax[1].set_title('True labels', fontsize=18)\n",
    "ax[1].scatter(train_data[:, 2], train_data[:, 3], c=train_labels, s=150, edgecolor='k', cmap=\"plasma\")\n",
    "ax[1].set_xlabel('Petal length', fontsize=18)\n",
    "ax[1].set_ylabel('Petal width', fontsize=18)\n",
    "ax[1].tick_params(direction='in', length=10, width=5, colors='k', labelsize=20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We implement a method to plot K-Means results in Iris database and establish a centralised model which will be our reference model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shfl.model.kmeans_model import KMeansModel\n",
    "\n",
    "def plot_k_means(km, X, title):\n",
    "    new_labels = km.predict(X)\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16,8))\n",
    "    fig.suptitle(title, fontsize=20)\n",
    "    axes[0].scatter(X[:, 0], X[:, 1], c=new_labels, cmap='plasma', edgecolor='k', s=150)\n",
    "    axes[0].set_xlabel('Sepal length', fontsize=18)\n",
    "    axes[0].set_ylabel('Sepal width', fontsize=18)\n",
    "    axes[0].tick_params(direction='in', length=10, width=5, colors='k', labelsize=20)\n",
    "    axes[0].set_title('Predicted', fontsize=18)\n",
    "    \n",
    "    axes[1].scatter(X[:, 2], X[:, 3], c=new_labels, cmap='plasma', edgecolor='k', s=150)\n",
    "    axes[1].set_xlabel('Petal length', fontsize=18)\n",
    "    axes[1].set_ylabel('Petal width', fontsize=18)\n",
    "    axes[1].tick_params(direction='in', length=10, width=5, colors='k', labelsize=20) \n",
    "    axes[1].set_title('Predicted', fontsize=18)\n",
    "    \n",
    "# Plot train data:\n",
    "centralized_model = KMeansModel(n_clusters=3, n_features = train_data.shape[1], init = np.zeros((3,4)))\n",
    "centralized_model.train(train_data)\n",
    "\n",
    "print(centralized_model.get_model_params())\n",
    "plot_k_means(centralized_model, train_data, title = \"Benchmark: K-means using centralized data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How to aggregate model's parameters from each federated node in clustering** <br/>\n",
    "\n",
    "Since the labels of clusters can vary among each node, we cannot average the centroids right away. \n",
    "A solution is to choose the lowest distance average: this is achieved by simply applying the k-means algorithm on the centroids coordinates of all nodes. \n",
    "In [ClusterFedAvgAggregator](../shfl/federated_aggregator/cluster_fedavg_aggregator.py) you can see its implementation.\n",
    "\n",
    "**Remark**: this implementation is based on the assumption that the number of clusters is previously fixed across the clients, so it only works properly in I.I.D scenarios (see [Federated Sampling](./federated_sampling.ipynb)). We are working in a federated aggregation operator which works in every distribution of data across clients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shfl.federated_aggregator.cluster_fedavg_aggregator import ClusterFedAvgAggregator\n",
    "\n",
    "# Create the IID data: \n",
    "iid_distribution = shfl.data_distribution.IidDataDistribution(database)\n",
    "federated_data, test_data, test_label = iid_distribution.get_federated_data(num_nodes = 12, percent=100)\n",
    "print(\"Number of nodes: \" + str(federated_data.num_nodes()))\n",
    "\n",
    "# Run the algorithm:\n",
    "aggregator = ClusterFedAvgAggregator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to run our model in a federated configuration. \n",
    "\n",
    "The performance is assessed by several clustering metrics (see [this link](https://scikit-learn.org/stable/modules/clustering.html#clustering-evaluation)).\n",
    "\n",
    "For reference, below we compare the metrics of:\n",
    " - Each node; \n",
    " - The global (federated) model;\n",
    " - The centralized (non-federated) model.\n",
    " \n",
    "It can be observed that the performance of *Global federated model* is in general superior with respect to the performance of each node, thus the federated learning approach proves to be beneficial. Moreover, the performance of the Global federated model is very close to the performance of the centralized model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shfl.federated_government.federated_government import FederatedGovernment\n",
    "\n",
    "n_clusters = 3 # Set number of clusters\n",
    "n_features = train_data.shape[1]\n",
    "def model_builder():\n",
    "    model = KMeansModel(n_clusters=n_clusters, n_features = n_features)\n",
    "    return model\n",
    "\n",
    "\n",
    "federated_government = FederatedGovernment(model_builder, federated_data, aggregator)\n",
    "print(\"Test data size: \" + str(test_data.shape[0]))\n",
    "print(\"\\n\")\n",
    "federated_government.run_rounds(n = 3, test_data = test_data, test_label = test_label)\n",
    "\n",
    "# Reference Centralized (non federate) model:\n",
    "print(\"Centralized model test performance : \" + str(centralized_model.evaluate(data=test_data, labels=test_labels)))\n",
    "plot_k_means(centralized_model, test_data, title = \"Benchmark on Test data: K-means using CENTRALIZED data\")\n",
    "plot_k_means(federated_government.global_model, test_data, title = \"Benchmark on Test data: K-means using FL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Differentially Private version**\n",
    "\n",
    "To preserve the privacy of the clients, in this section we introduce Differential Privacy (DP) in our model. Firstly we calibrate the noise introduced by the differentially private mechanism using the train data, then we apply DP to each client feature, so that each cluster computed by a client is shared with the main server privately, that is, without disclosing client's identity.\n",
    "\n",
    "In the case of applying the Gaussian privacy mechanism , the noise added has to be of the order of the sensitivity of the model's output, i.e. the coordinates of each cluster.\n",
    "\n",
    "In the general case, the model's sensitivity might be difficult to compute analytically. \n",
    "An alternative approach is to attain *random* differential privacy through a sampling over the data.\n",
    "\n",
    "That is, instead of computing analytically the *global* sensitivity $\\Delta f$, we compute an *empirical estimation* of it by sampling over the dataset.\n",
    "This approach is very convenient since allows for the sensitivity estimation of an arbitrary model or a black-box computer function.\n",
    "The \\texttt{Sherpa.FL} framework provides this functionality in the class `SensitivitySampler`.\n",
    "\n",
    "In order to carry out this approach, we need to specify a distribution of the data to sample from. \n",
    "This in general requires previous knowledge and/or model assumptions. \n",
    "However, in our specific case of manufactured data, we may assume that the data distribution is *uniform*. \n",
    "To the end, we define our class of `ProbabilityDistribution` that uniformly samples over a data-frame.\n",
    "Moreover, we assume that we do have access to a set of data (this can be thought, for example, as some reference public data set). \n",
    "In this example, we generate a $\\textit{new}$ dataset, and use its train partition for sampling:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class UniformDistribution(shfl.differential_privacy.ProbabilityDistribution):\n",
    "    \"\"\"\n",
    "    Implement Uniform sampling over the data\n",
    "    \"\"\"\n",
    "    def __init__(self, sample_data):\n",
    "        self._sample_data = sample_data\n",
    "\n",
    "    def sample(self, sample_size):\n",
    "        row_indices = np.random.randint(low=0, high=self._sample_data.shape[0], size=sample_size, dtype='l')\n",
    "        \n",
    "        return self._sample_data[row_indices, :]\n",
    "    \n",
    "sample_data = train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class `SensitivitySampler` implements the sampling given a *query*, i.e. the learning model itself in this case.\n",
    "We only need to add the method `get` to our model since it is required by the class `SensitivitySampler`. \n",
    "We choose the sensitivity norm to be the v norm and we apply the sampling. \n",
    "The value of the sensitivity depends on the number of samples `n`: the more samples we perform, the more accurate the sensitivity. \n",
    "Indeed, increasing the number of samples `n`, the sensitivity gets more accurate and typically decreases. \n",
    "\n",
    "Unfortunately, sampling over a dataset involves, at each sample, the training of the model on two datasets differing in one entry.\n",
    "Thus in general this procedure might be computationally expensive (e.g. in the case of training a deep neuronal network)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shfl.differential_privacy import SensitivitySampler\n",
    "from shfl.differential_privacy import L2SensitivityNorm\n",
    "\n",
    "class KMeansSample(KMeansModel):\n",
    "    \n",
    "    def __init__(self, feature, **kargs):\n",
    "        self._feature = feature\n",
    "        super().__init__(**kargs)\n",
    "    \n",
    "    def get(self, data_array):\n",
    "        self.train(data_array)\n",
    "        params = self.get_model_params()\n",
    "        return params[:, self._feature]\n",
    "\n",
    "distribution = UniformDistribution(sample_data)\n",
    "sampler = SensitivitySampler()\n",
    "# Reproducibility\n",
    "np.random.seed(789)\n",
    "n_samples = 50\n",
    "\n",
    "sensitivities = np.empty(n_features)\n",
    "\n",
    "for i in range(n_features):\n",
    "    model = KMeansSample(feature=i, n_clusters=n_clusters, n_features=n_features)\n",
    "    sensitivities[i], _ = sampler.sample_sensitivity(model, L2SensitivityNorm(), distribution, n=n_samples, gamma=0.05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Max sensitivity from sampling: \", np.max(sensitivities))\n",
    "print(\"Min sensitivity from sampling: \", np.min(sensitivities))\n",
    "print(\"Mean sensitivity from sampling:\", np.mean(sensitivities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from shfl.differential_privacy import GaussianMechanism\n",
    "from shfl.private.data import DPDataAccessDefinition\n",
    "\n",
    "class CustomAccess(DPDataAccessDefinition):\n",
    "    \n",
    "    def __init__(self, sensitivity_array, epsilon_delta):\n",
    "        self._epsilon_delta = epsilon_delta\n",
    "        self._sensitivity_array = sensitivity_array\n",
    "\n",
    "    @property    \n",
    "    def epsilon_delta(self):\n",
    "        return self._epsilon_delta\n",
    "    \n",
    "    def apply(self, data):\n",
    "        for i in range(len(self._sensitivity_array)):\n",
    "            dpm = GaussianMechanism(sensitivity=self._sensitivity_array[i], epsilon_delta=self._epsilon_delta)\n",
    "            data[:,i] = dpm.apply(data[:,i])\n",
    "        return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally if the model has more than one feature, it is a bad idea to estimate the sensitivity for all of the features at the same time as the features may have wildly varying sensitivities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpm = CustomAccess(sensitivity_array=sensitivities, epsilon_delta=(0.9, 0.9))\n",
    "federated_government = FederatedGovernment(\n",
    "    model_builder, federated_data, aggregator, model_params_access = dpm)\n",
    "print(\"Test data size: \" + str(test_data.shape[0]))\n",
    "print(\"\\n\")\n",
    "federated_government.run_rounds(n = 1, test_data = test_data, test_label = test_label)\n",
    "\n",
    "# Reference Centralized (non federate) model:\n",
    "print(\"Centralized model test performance : \" + str(centralized_model.evaluate(data=test_data, labels=test_labels)))\n",
    "plot_k_means(centralized_model, test_data, title = \"Benchmark on Test data: K-means using CENTRALIZED data\")\n",
    "plot_k_means(federated_government.global_model, test_data, title = \"Benchmark on Test data: K-means using FL and DP\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see when we add DP to the model it becomes quite unstable (multiple executions each one with very different results) and almost useless (even with unacceptable values for $\\delta$, that is $\\delta \\geq 0.5$, the results are quite bad), which suggest that another way of adding DP have to be provided. An alternative approach for adding DP can be found in [A differential privacy protecting K-means clustering algorithm based on contour coefficients](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0206832), but still it is unclear how to adapt it in a federated setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
