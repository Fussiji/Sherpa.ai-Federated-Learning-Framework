{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Federated learning: Aggregation operators\n",
    "\n",
    "In this notebook we provide an explanation of the implementation of the different federated aggregation operators provided in the platform. Before discussing the different aggregation operators, we establish the federated configuration (for more information see [Basic Concepts Notebook](./basic_concepts.ipynb))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import shfl\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "database = shfl.data_base.Emnist()\n",
    "train_data, train_labels, test_data, test_labels = database.load_data()\n",
    "\n",
    "iid_distribution = shfl.data_distribution.IidDataDistribution(database)\n",
    "federated_data, test_data, test_labels = iid_distribution.get_federated_data(num_nodes=5, percent=10)\n",
    "\n",
    "def model_builder():\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu', strides=1, input_shape=(28, 28, 1)))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=2, strides=2, padding='valid'))\n",
    "    model.add(tf.keras.layers.Dropout(0.4))\n",
    "    model.add(tf.keras.layers.Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu', strides=1))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=2, strides=2, padding='valid'))\n",
    "    model.add(tf.keras.layers.Dropout(0.3))\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dropout(0.1))\n",
    "    model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    \n",
    "    return shfl.model.DeepLearningModel(model)\n",
    "\n",
    "\n",
    "class Reshape(shfl.private.FederatedTransformation):\n",
    "    \n",
    "    def apply(self, labeled_data):\n",
    "        labeled_data.data = np.reshape(labeled_data.data, (labeled_data.data.shape[0], labeled_data.data.shape[1], labeled_data.data.shape[2],1))\n",
    "        \n",
    "shfl.private.federated_operation.apply_federated_transformation(federated_data, Reshape())\n",
    "\n",
    "class Normalize(shfl.private.FederatedTransformation):\n",
    "    \n",
    "    def __init__(self, mean, std):\n",
    "        self.__mean = mean\n",
    "        self.__std = std\n",
    "    \n",
    "    def apply(self, labeled_data):\n",
    "        labeled_data.data = (labeled_data.data - self.__mean)/self.__std\n",
    "        \n",
    "        \n",
    "mean = np.mean(train_data.data)\n",
    "std = np.std(train_data.data)\n",
    "shfl.private.federated_operation.apply_federated_transformation(federated_data, Normalize(mean, std))\n",
    "\n",
    "test_data = np.reshape(test_data, (test_data.shape[0], test_data.shape[1], test_data.shape[2],1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have loaded and federated the data and established the learning model, it only remains to establish the aggregation operator. At the moment, we have implemented: FedAvg and WeightedFedAvg. The implementation of the federated aggregation operators are as follows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Federated Averaging (`FedAvg`) Operator\n",
    "\n",
    "In this section, we detail the implementation of FedAvg (see [FedAVg](https://github.com/sherpaai/Sherpa.FL/blob/master/shfl/federated_aggregator/avgfed_aggregator.py)) proposed  by Google in this [paper](https://arxiv.org/abs/1602.05629). \n",
    "\n",
    "It is based on the arithmetic mean of the local weights $W_i$ trained in each of the local clients $C_i$. That is, the weights $W$ of the global model after each round of training are\n",
    "\n",
    "$$W = \\frac{1}{n_{\\rm{C}}} \\sum_{i=1}^{n_{\\rm{C}}} W_i$$\n",
    "\n",
    "\n",
    "For its implementation, we create a class that implements [FederatedAggregator](https://github.com/sherpaai/Sherpa.FL/blob/master/shfl/federated_aggregator/federated_aggregator.py) interface. The method aggregate_weights is overwritten calculating the mean of the local weights of each client. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from shfl.federated_aggregator.federated_aggregator import FederatedAggregator\n",
    "\n",
    "\n",
    "class FedAvgAggregator(FederatedAggregator):\n",
    "    \"\"\"\n",
    "    Implementation of Federated Averaging Aggregator. It only uses a simple average of the parameters of all the models\n",
    "    \"\"\"\n",
    "\n",
    "    def aggregate_weights(self, clients_params):\n",
    "        clients_params_array = np.array(clients_params)\n",
    "\n",
    "        num_clients = clients_params_array.shape[0]\n",
    "        num_layers = clients_params_array.shape[1]\n",
    "        clients_params_array = clients_params_array.reshape(num_clients, num_layers)\n",
    "\n",
    "        aggregated_weights = np.array([np.mean(clients_params_array[:, layer], axis=0) for layer in range(num_layers)])\n",
    "\n",
    "        return aggregated_weights\n",
    "\n",
    "\n",
    "fedavg_aggregator = FedAvgAggregator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weighted Federated Averaging (`WeightedFedAvg`) Operator\n",
    "\n",
    "In this section, we detail the implementation of `WeightedFedAvg` (see [WeightedFedAVg](../shfl/federated_aggregator/weighted_avgfed_aggregator.py)). It is the weighted version of `FedAvg`. The weight of each client $C_i$ is determined by the amount of client's data $n_i$ with respect to total training data $n$. That is, the parameters $W$ of the global model after each round of training are \n",
    "\n",
    "$$W =  \\sum_{i=1}^n \\frac{n_i}{n} W_i$$\n",
    "\n",
    "When all clients have the same amount of data it is equivalent to FedAvg.\n",
    "\n",
    "For its implementation, we create a class that implements `FederatedAggregator` interface. The method `aggregate_weights` is overwritten calculating the weighted mean of the local parameters of each client. For that purpose, we first ponderate the local parameters by the percentage and, after that, we sum the ponderated parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from shfl.federated_aggregator.federated_aggregator import FederatedAggregator\n",
    "\n",
    "\n",
    "class WeightedFedAvgAggregator(FederatedAggregator):\n",
    "    \"\"\"\n",
    "    Implementation of Weighted Federated Averaging Aggregator. The aggregation of the parameters is based in the number of data \\\n",
    "    in every node.\n",
    "    \"\"\"\n",
    "\n",
    "    def aggregate_weights(self, clients_params):\n",
    "        clients_params_array = np.array(clients_params)\n",
    "\n",
    "        num_clients = clients_params_array.shape[0]\n",
    "        num_layers = clients_params_array.shape[1]\n",
    "        clients_params_array = clients_params_array.reshape(num_clients, num_layers)\n",
    "\n",
    "        ponderated_weights = np.array([self._percentage[client] * clients_params_array[client, :] for client in range(num_clients)])\n",
    "        aggregated_weights = np.array([np.sum(ponderated_weights[:, layer], axis=0) for layer in range(num_layers)])\n",
    "\n",
    "        return aggregated_weights\n",
    "    \n",
    "weighted_fedavg_aggregator = WeightedFedAvgAggregator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we are ready to establish the federated government with any of the implemented aggregation operators and start the federated learning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "federated_government = shfl.federated_government.FederatedGovernment(model_builder, federated_data, fedavg_aggregator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "federated_government.run_rounds(1, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IOWA Federated Aggregation Operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shfl.federated_government.iowa_federated_government import IowaFederatedGovernment\n",
    "\n",
    "iowa_federated_government = IowaFederatedGovernment(model_builder, federated_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iowa_federated_government.run_rounds(1, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
