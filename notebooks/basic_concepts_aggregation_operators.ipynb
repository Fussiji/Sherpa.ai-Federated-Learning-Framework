{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Federated learning: Aggregation operators\n",
    "\n",
    "In this notebook we provide an explanation of the implementation of the different federated aggregation operators provided in the platform. Before discussing the different aggregation operators, we establish the federated configuration (for more information see [Basic Concepts Notebook](./basic_concepts.ipynb))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import shfl\n",
    "import keras\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "database = shfl.data_base.Emnist()\n",
    "train_data, train_labels, val_data, val_labels, test_data, test_labels = database.load_data()\n",
    "\n",
    "iid_distribution = shfl.data_distribution.IidDataDistribution(database)\n",
    "federated_data, test_data, test_labels = iid_distribution.get_federated_data(num_nodes=20, percent=10)\n",
    "\n",
    "def model_builder():\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu', strides=1, input_shape=(28, 28, 1)))\n",
    "    model.add(keras.layers.MaxPooling2D(pool_size=2, strides=2, padding='valid'))\n",
    "    model.add(keras.layers.Dropout(0.4))\n",
    "    model.add(keras.layers.Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu', strides=1))\n",
    "    model.add(keras.layers.MaxPooling2D(pool_size=2, strides=2, padding='valid'))\n",
    "    model.add(keras.layers.Dropout(0.3))\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(128, activation='relu'))\n",
    "    model.add(keras.layers.Dropout(0.1))\n",
    "    model.add(keras.layers.Dense(64, activation='relu'))\n",
    "    model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    \n",
    "    return shfl.model.DeepLearningModel(model)\n",
    "\n",
    "\n",
    "class Reshape(shfl.private.FederatedTransformation):\n",
    "    \n",
    "    def apply(self, labeled_data):\n",
    "        labeled_data.data = np.reshape(labeled_data.data, (labeled_data.data.shape[0], labeled_data.data.shape[1], labeled_data.data.shape[2],1))\n",
    "        \n",
    "shfl.private.federated_operation.apply_federated_transformation(federated_data, Reshape())\n",
    "\n",
    "class Normalize(shfl.private.FederatedTransformation):\n",
    "    \n",
    "    def __init__(self, mean, std):\n",
    "        self.__mean = mean\n",
    "        self.__std = std\n",
    "    \n",
    "    def apply(self, labeled_data):\n",
    "        labeled_data.data = (labeled_data.data - self.__mean)/self.__std\n",
    "        \n",
    "        \n",
    "mean = np.mean(train_data.data)\n",
    "std = np.std(train_data.data)\n",
    "shfl.private.federated_operation.apply_federated_transformation(federated_data, Normalize(mean, std))\n",
    "\n",
    "test_data = np.reshape(test_data, (test_data.shape[0], test_data.shape[1], test_data.shape[2],1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have loaded and federated the data and established the learning model, it only remains to establish the aggregation operator. At the moment, the framework provides two aggregation mechanism: FedAvg and WeightedFedAvg. The implementation of the federated aggregation operators are as follows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Federated Averaging (FedAvg) Operator\n",
    "\n",
    "In this section, we detail the implementation of FedAvg (see [FedAVg](../shfl/federated_aggregator/avgfed_aggregator.py)) proposed  by Google in this [paper](https://arxiv.org/abs/1602.05629). \n",
    "\n",
    "It is based on the arithmetic mean of the local params $W_i$ trained in each of the local clients $C_i$. That is, the params $W$ of the global model after each round of training are\n",
    "\n",
    "$$W = \\frac{1}{n} \\sum_{i=1}^n W_i$$\n",
    "\n",
    "\n",
    "For its implementation, we create a class that implements [FederatedAggregator](../shfl/federated_aggregator/federated_aggregator.py) interface. The method aggregate_weights is overwritten calculating the mean of the local params of each client. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from shfl.federated_aggregator.federated_aggregator import FederatedAggregator\n",
    "\n",
    "\n",
    "class AvgFedAggregator(FederatedAggregator):\n",
    "    \"\"\"\n",
    "    Implementation of Average Federated Aggregator. It only uses a simple average of the parameters of all the models\n",
    "    \"\"\"\n",
    "\n",
    "    def aggregate_weights(self, clients_params):\n",
    "        clients_params_array = np.array(clients_params)\n",
    "\n",
    "        num_clients = clients_params_array.shape[0]\n",
    "        num_layers = clients_params_array.shape[1]\n",
    "        clients_params_array = clients_params_array.reshape(num_clients, num_layers)\n",
    "\n",
    "        aggregated_weights = np.array([np.mean(clients_params_array[:, layer], axis=0) for layer in range(num_layers)])\n",
    "\n",
    "        return aggregated_weights\n",
    "\n",
    "\n",
    "fedavg_aggregator = AvgFedAggregator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weighted Federated Averaging (WeightedFedAvg) Operator\n",
    "\n",
    "In this section, we detail the implementation of WeightedFedAvg (see [WeightedFedAVg](../shfl/federated_aggregator/weighted_avgfed_aggregator.py)). It is the weighted version of FedAvg. The weight of each client $C_i$ is determined by the amount of client data $n_i$ with respect to total training data $n$. That is, the params $W$ of the global model after each round of training are \n",
    "\n",
    "$$W =  \\sum_{i=1}^n \\frac{n_i}{n} W_i$$\n",
    "\n",
    "When all clients have the same amount of data it is equivalent to FedAvg.\n",
    "\n",
    "For its implementation, we create a class that implements FederatedAggregator interface. The method aggregate_weights is overwritten calculating the weighted mean of the local params of each client. For that purpose, we first ponderate the local params using the parameter percentage and, after that, we sum the ponderated params."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from shfl.federated_aggregator.federated_aggregator import FederatedAggregator\n",
    "\n",
    "\n",
    "class WeightedAvgFedAggregator(FederatedAggregator):\n",
    "    \"\"\"\n",
    "    Implementation of Average Federated Aggregator. The aggregation of the parameters is based in the number of data \\\n",
    "    in every node.\n",
    "    \"\"\"\n",
    "\n",
    "    def aggregate_weights(self, clients_params):\n",
    "        clients_params_array = np.array(clients_params)\n",
    "\n",
    "        num_clients = clients_params_array.shape[0]\n",
    "        num_layers = clients_params_array.shape[1]\n",
    "        clients_params_array = clients_params_array.reshape(num_clients, num_layers)\n",
    "\n",
    "        ponderated_weights = np.array([self._percentage[client] * clients_params_array[client, :] for client in range(num_clients)])\n",
    "        aggregated_weights = np.array([np.sum(ponderated_weights[:, layer], axis=0) for layer in range(num_layers)])\n",
    "\n",
    "        return aggregated_weights\n",
    "    \n",
    "weighted_fedavg_aggregator = WeightedAvgFedAggregator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we are ready to establish de federated goverment with any of the implemented aggregation operators and start the federated learning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "federated_government = shfl.learning_approach.FederatedGovernment(model_builder, federated_data, fedavg_aggregator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy round 0\n",
      "Test performance client <shfl.private.federated_operation.FederatedDataNode object at 0x117596e90>: [5.310560375308991, 0.6539000272750854]\n",
      "Test performance client <shfl.private.federated_operation.FederatedDataNode object at 0x1a2caab550>: [4.772594417381287, 0.6820250153541565]\n",
      "Test performance client <shfl.private.federated_operation.FederatedDataNode object at 0x1a2caab6d0>: [4.493043189811707, 0.6985750198364258]\n",
      "Test performance client <shfl.private.federated_operation.FederatedDataNode object at 0x1a2caab890>: [4.651841709518433, 0.6874499917030334]\n",
      "Test performance client <shfl.private.federated_operation.FederatedDataNode object at 0x1a2caaba50>: [4.808404593467713, 0.6800749897956848]\n",
      "Test performance client <shfl.private.federated_operation.FederatedDataNode object at 0x1a2caabd10>: [3.9967662153720855, 0.7358250021934509]\n",
      "Test performance client <shfl.private.federated_operation.FederatedDataNode object at 0x1a2caabe10>: [5.738841980648041, 0.6251500248908997]\n",
      "Test performance client <shfl.private.federated_operation.FederatedDataNode object at 0x1a2cabb050>: [6.602431640625, 0.5516250133514404]\n",
      "Test performance client <shfl.private.federated_operation.FederatedDataNode object at 0x1a2cabb1d0>: [4.06071819601059, 0.7279250025749207]\n",
      "Test performance client <shfl.private.federated_operation.FederatedDataNode object at 0x1a2cabb3d0>: [5.101232486057281, 0.663100004196167]\n",
      "Test performance client <shfl.private.federated_operation.FederatedDataNode object at 0x1a2cabb510>: [5.2010588116645815, 0.6607249975204468]\n",
      "Test performance client <shfl.private.federated_operation.FederatedDataNode object at 0x1a2cabb6d0>: [4.6816134460449215, 0.6840500235557556]\n",
      "Test performance client <shfl.private.federated_operation.FederatedDataNode object at 0x1a2cabb890>: [7.551041991043091, 0.5055500268936157]\n",
      "Test performance client <shfl.private.federated_operation.FederatedDataNode object at 0x1a2cabba50>: [5.055827945232392, 0.6679250001907349]\n",
      "Test performance client <shfl.private.federated_operation.FederatedDataNode object at 0x1a2cabbc10>: [4.042423392939567, 0.7265999913215637]\n",
      "Test performance client <shfl.private.federated_operation.FederatedDataNode object at 0x1a2cabbdd0>: [4.29935334982872, 0.7081249952316284]\n",
      "Test performance client <shfl.private.federated_operation.FederatedDataNode object at 0x1a2cabbf90>: [4.5230098672866825, 0.699999988079071]\n",
      "Test performance client <shfl.private.federated_operation.FederatedDataNode object at 0x1a2cabf190>: [5.195849438762664, 0.6523000001907349]\n",
      "Test performance client <shfl.private.federated_operation.FederatedDataNode object at 0x1a2cabf350>: [6.962764186477661, 0.5532000064849854]\n",
      "Test performance client <shfl.private.federated_operation.FederatedDataNode object at 0x1a2cabf510>: [4.30692459807396, 0.7093499898910522]\n",
      "Global model test performance : [3.9250435561180113, 0.7217249870300293]\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "federated_government.run_rounds(1, test_data, test_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
