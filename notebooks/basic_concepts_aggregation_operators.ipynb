{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Federated learning: Aggregation operators\n",
    "\n",
    "In this notebook we provide an explanation of the implementation of the different federated aggregation operators provided in the platform. Before discussing the different aggregation operators, we establish the federated configuration (for more information see [Basic Concepts Notebook](./basic_concepts.ipynb))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import shfl\n",
    "import keras\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "database = shfl.data_base.Emnist()\n",
    "train_data, train_labels, val_data, val_labels, test_data, test_labels = database.load_data()\n",
    "\n",
    "iid_distribution = shfl.data_distribution.IidDataDistribution(database)\n",
    "federated_data, test_data, test_labels = iid_distribution.get_federated_data(num_nodes=20, percent=10)\n",
    "\n",
    "def model_builder():\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu', strides=1, input_shape=(28, 28, 1)))\n",
    "    model.add(keras.layers.MaxPooling2D(pool_size=2, strides=2, padding='valid'))\n",
    "    model.add(keras.layers.Dropout(0.4))\n",
    "    model.add(keras.layers.Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu', strides=1))\n",
    "    model.add(keras.layers.MaxPooling2D(pool_size=2, strides=2, padding='valid'))\n",
    "    model.add(keras.layers.Dropout(0.3))\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(128, activation='relu'))\n",
    "    model.add(keras.layers.Dropout(0.1))\n",
    "    model.add(keras.layers.Dense(64, activation='relu'))\n",
    "    model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    \n",
    "    return shfl.model.DeepLearningModel(model)\n",
    "\n",
    "\n",
    "class Reshape(shfl.private.FederatedTransformation):\n",
    "    \n",
    "    def apply(self, labeled_data):\n",
    "        labeled_data.data = np.reshape(labeled_data.data, (labeled_data.data.shape[0], labeled_data.data.shape[1], labeled_data.data.shape[2],1))\n",
    "        \n",
    "shfl.private.federated_operation.apply_federated_transformation(federated_data, Reshape())\n",
    "\n",
    "class Normalize(shfl.private.FederatedTransformation):\n",
    "    \n",
    "    def __init__(self, mean, std):\n",
    "        self.__mean = mean\n",
    "        self.__std = std\n",
    "    \n",
    "    def apply(self, labeled_data):\n",
    "        labeled_data.data = (labeled_data.data - self.__mean)/self.__std\n",
    "        \n",
    "        \n",
    "mean = np.mean(train_data.data)\n",
    "std = np.std(train_data.data)\n",
    "shfl.private.federated_operation.apply_federated_transformation(federated_data, Normalize(mean, std))\n",
    "\n",
    "test_data = np.reshape(test_data, (test_data.shape[0], test_data.shape[1], test_data.shape[2],1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have loaded, federated the data and established the learning model, it only remains to establish the aggregation operator. At the moment, the framework provides two aggregation mechanism: FedAvg and WeightedFedAvg. The implementation of the federated aggregation operators are as follows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Federated Averaging (FedAvg) Operator\n",
    "\n",
    "In this section, we detail the implementation of FedAvg (see [FedAVg](../shfl/federated_aggregator/fedavg_aggregator.py)) proposed  by Google in this [paper](https://arxiv.org/abs/1602.05629). \n",
    "\n",
    "It is based on the arithmetic mean of the local params $W_i$ trained in each of the local clients $C_i$. That is, the params $W$ of the global model after each round of training are\n",
    "\n",
    "$$W = \\frac{1}{n} \\sum_{i=1}^n W_i$$\n",
    "\n",
    "\n",
    "For its implementation, we create a class that implements [FederatedAggregator](../shfl/federated_aggregator/federated_aggregator.py) interface. The method aggregate_weights is overwritten calculating the mean of the local params of each client. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from shfl.federated_aggregator.federated_aggregator import FederatedAggregator\n",
    "\n",
    "\n",
    "class FedAvgAggregator(FederatedAggregator):\n",
    "    \"\"\"\n",
    "    Implementation of Federated Averaging Aggregator. It only uses a simple average of the parameters of all the models\n",
    "    \"\"\"\n",
    "\n",
    "    def aggregate_weights(self, clients_params):\n",
    "        clients_params_array = np.array(clients_params)\n",
    "\n",
    "        num_clients = clients_params_array.shape[0]\n",
    "        num_layers = clients_params_array.shape[1]\n",
    "        clients_params_array = clients_params_array.reshape(num_clients, num_layers)\n",
    "\n",
    "        aggregated_weights = np.array([np.mean(clients_params_array[:, layer], axis=0) for layer in range(num_layers)])\n",
    "\n",
    "        return aggregated_weights\n",
    "\n",
    "\n",
    "fedavg_aggregator = FedAvgAggregator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weighted Federated Averaging (WeightedFedAvg) Operator\n",
    "\n",
    "In this section, we detail the implementation of WeightedFedAvg (see [WeightedFedAVg](../shfl/federated_aggregator/weighted_fedavg_aggregator.py)). It is the weighted version of FedAvg. The weight of each client $C_i$ is determined by the amount of client data $n_i$ with respect to total training data $n$. That is, the params $W$ of the global model after each round of training are \n",
    "\n",
    "$$W =  \\sum_{i=1}^n \\frac{n_i}{n} W_i$$\n",
    "\n",
    "When all clients have the same amount of data it is equivalent to FedAvg.\n",
    "\n",
    "For its implementation, we create a class that implements FederatedAggregator interface. The method aggregate_weights is overwritten calculating the weighted mean of the local params of each client. For that purpose, we first ponderate the local params using the parameter percentage and, after that, we sum the ponderated params."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from shfl.federated_aggregator.federated_aggregator import FederatedAggregator\n",
    "\n",
    "\n",
    "class WeightedFedAvgAggregator(FederatedAggregator):\n",
    "    \"\"\"\n",
    "    Implementation of Weighted Federated Averaging Aggregator. The aggregation of the parameters is based in the number of data \\\n",
    "    in every node.\n",
    "    \"\"\"\n",
    "\n",
    "    def aggregate_weights(self, clients_params):\n",
    "        clients_params_array = np.array(clients_params)\n",
    "\n",
    "        num_clients = clients_params_array.shape[0]\n",
    "        num_layers = clients_params_array.shape[1]\n",
    "        clients_params_array = clients_params_array.reshape(num_clients, num_layers)\n",
    "\n",
    "        ponderated_weights = np.array([self._percentage[client] * clients_params_array[client, :] for client in range(num_clients)])\n",
    "        aggregated_weights = np.array([np.sum(ponderated_weights[:, layer], axis=0) for layer in range(num_layers)])\n",
    "\n",
    "        return aggregated_weights\n",
    "    \n",
    "weighted_fedavg_aggregator = WeightedFedAvgAggregator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we are ready to establish the federated government with any of the implemented aggregation operators and start the federated learning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "federated_government = shfl.learning_approach.FederatedGovernment(model_builder, federated_data, fedavg_aggregator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "federated_government.run_rounds(1, test_data, test_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
