{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Federated learning: Simple experiment\n",
    "\n",
    "In this notebook we provide a simple example of how to make an experiment of a federated environment with the help of this framework. We are going to use a popular dataset to start the experimentation in a federated environment. The framework provides some functions to load the [Emnist](https://www.nist.gov/itl/products-and-services/emnist-dataset) Digits dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shfl\n",
    "\n",
    "database = shfl.data_base.Emnist()\n",
    "train_data, train_labels, val_data, val_labels, test_data, test_labels = database.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect some properties of the loaded data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_data))\n",
    "print(len(val_data))\n",
    "print(len(test_data))\n",
    "print(type(train_data[0]))\n",
    "train_data[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, as we have seen, our dataset is composed by a set of matrixes of 28 by 28. Before starting with the federated scenario, we can take a look to a sample in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(train_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to simulate a federated learning scenario with a set of client nodes containing private data, and a central server that will be responsible to coordinate the different clients. But, first of all, we have to simulate the data contained in every client. In order to do that, we are going to use the previous dataset loaded. The assumption in this example will be the data is distributed as a set of independent and identically distributed random variables, having every node more o less the same amount of data. There are a set of different posibilities in order to distribute the data. The distribution of the data is one of the factor that could impact more to a federated algorithm. Therefore, the framework contains the implementation of some of the most common distribution that allow you experiment different situations easily. In this [link]() you can dig into the options that the framework provides at the moment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iid_distribution = shfl.data_distribution.IidDataDistribution(database)\n",
    "federated_data, test_data, test_label = iid_distribution.get_federated_data(num_nodes=20, percent=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it. We have created federated data from the Emnist dataset with 20 nodes and using only 10 percent of the available data. This data is a set of data nodes containing private data. This private data needs a identifier that we have provided in the creation of the federated data, in this case \"emnist\". Let's learn a little about the federated data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(federated_data))\n",
    "print(federated_data.num_nodes())\n",
    "federated_data[0].private_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, private data in a node is not accesible directly but the framework provides mechanisms to use this data in a machine learning model. A federated learning algorithm is defined by a local model to learn from data in every node and a way to aggregate the different model parameters in a central node. In this example we will use a deep learning model using keras to build it. The framework provides a class to adapt a Keras model to the framework, your job is only create a function that will act as model builder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#If you want execute in GPU, you must uncomment this two lines.\n",
    "# physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "# tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "class CustomDense(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Implementation of Linear layer\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    units : int\n",
    "        number of units for the output\n",
    "    w : matrix\n",
    "        Weights from the layer\n",
    "    b : array\n",
    "        Bias from the layer\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, units=32):\n",
    "        super(CustomDense, self).__init__()\n",
    "        self._units = units\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        \"\"\"\n",
    "        Method for build the params\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        input_shape: list\n",
    "            size of inputs\n",
    "        \"\"\"\n",
    "        self._w = self.add_weight(shape=(input_shape[-1], self._units),\n",
    "                                  initializer='random_normal',\n",
    "                                  trainable=True)\n",
    "\n",
    "        self._b = self.add_weight(shape=(self._units,),\n",
    "                                  initializer='random_normal',\n",
    "                                  trainable=True)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \"\"\"\n",
    "        Apply linear layer\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        inputs: matrix\n",
    "            Input data\n",
    "\n",
    "        Return\n",
    "        ------\n",
    "        result : matrix\n",
    "            the result of linear transformation of the data\n",
    "        \"\"\"\n",
    "        return tf.nn.bias_add(tf.matmul(inputs, self._w), self._b)\n",
    "\n",
    "\n",
    "def model_builder():\n",
    "    inputs = tf.keras.Input(shape=(28, 28, 1))\n",
    "    x = tf.keras.layers.Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu', strides=1)(inputs)\n",
    "    x = tf.keras.layers.MaxPooling2D(pool_size=2, strides=2, padding='valid')(x)\n",
    "    x = tf.keras.layers.Dropout(0.4)(x)\n",
    "    x = tf.keras.layers.Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu', strides=1)(x)\n",
    "    x = tf.keras.layers.MaxPooling2D(pool_size=2, strides=2, padding='valid')(x)\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    x = CustomDense(128)(x)\n",
    "    x = tf.nn.relu(x)\n",
    "    x = tf.keras.layers.Dropout(0.1)(x)\n",
    "    x = CustomDense(64)(x)\n",
    "    x = tf.nn.relu(x)\n",
    "    x = CustomDense(10)(x)\n",
    "    outputs = tf.nn.softmax(x)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    \n",
    "    return shfl.model.DeepLearningModel(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we a model to deploy over nodes a set of nodes with data. The only piece missing is the aggregation operator. Nevertheless the framework provides some aggregation operators that we can use inmediatly. In the following piece of code we define the federated algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregator = shfl.federated_aggregator.AvgFedAggregator()\n",
    "federated_government = shfl.learning_approach.FederatedGovernment(model_builder, federated_data, aggregator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to see all the aggregation operators you can follow the following [link](). Before executing the algorithm we want to make a data transformation. The good practise to do that is to define a federated operation that will be apply over every node. We want to reshape the data, so we define the following FederatedTransformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Reshape(shfl.private.FederatedTransformation):\n",
    "    \n",
    "    def apply(self, labeled_data):\n",
    "        labeled_data.data = np.reshape(labeled_data.data, (labeled_data.data.shape[0], labeled_data.data.shape[1], labeled_data.data.shape[2],1))\n",
    "\n",
    "class CastFloat(shfl.private.FederatedTransformation):\n",
    "    \n",
    "    def apply(self, labeled_data):\n",
    "        labeled_data.data = labeled_data.data.astype(np.float32)\n",
    "        \n",
    "shfl.private.federated_operation.apply_federated_transformation(federated_data, Reshape())\n",
    "shfl.private.federated_operation.apply_federated_transformation(federated_data, CastFloat())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to execute our federated learning algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = np.reshape(test_data, (test_data.shape[0], test_data.shape[1], test_data.shape[2],1))\n",
    "test_data = test_data.astype(np.float32)\n",
    "federated_government.run_rounds(3, test_data, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
